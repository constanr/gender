{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pos import count_pos\n",
    "import sentiment_feature_extraction\n",
    "import os, xml.etree.ElementTree as et, itertools\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_targets(datapath):\n",
    "    files_gender = {}\n",
    "    files_age = {}\n",
    "    with open(datapath+'truth.txt', 'rb') as truth:\n",
    "        lines = truth.readlines()\n",
    "        for line in lines:\n",
    "            files_gender[line.split(':::')[0]+'.xml'] = line.split(':::')[1]\n",
    "            files_age[line.split(':::')[0]+'.xml'] = line.split(':::')[2]\n",
    "    return files_gender, files_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tweets(language, year):\n",
    "    if year == '2015':\n",
    "        datapath = 'data/pan15-author-profiling-training-dataset-'+language+'-2015-04-23/'\n",
    "        files_gender, files_age = extract_targets(datapath)\n",
    "        files = os.listdir(datapath)\n",
    "        tweets = []\n",
    "        for f in files:\n",
    "            if f.endswith('.xml'):\n",
    "                posts = []\n",
    "                texts = ''\n",
    "                tree = et.parse(datapath+f)\n",
    "                documents = tree.iterfind('document')\n",
    "                for d in documents:\n",
    "                    texts += d.text+'\\n'\n",
    "                post = {}\n",
    "                post['text'] = texts\n",
    "                post['gender'] = files_gender[f]\n",
    "                post['age'] = files_age[f]\n",
    "                posts.append(post)\n",
    "                tweets.append(posts)\n",
    "        tweets = list(itertools.chain(*tweets))\n",
    "    elif year == '2016':\n",
    "        datapath = 'data/pan16-author-profiling-training-dataset-'+language+'-2016-02-29/'\n",
    "        files_gender, files_age = extract_targets(datapath)\n",
    "        files = os.listdir(datapath)\n",
    "        tweets = []\n",
    "        for f in files:\n",
    "            if f.endswith('.xml'):\n",
    "                posts = []\n",
    "                texts = ''\n",
    "                root = et.parse(datapath+f)\n",
    "                for d in root.find('documents').findall('document'):\n",
    "                    if d.text!=None:\n",
    "                        soup = BeautifulSoup(d.text, 'html.parser').get_text()\n",
    "                        texts += soup+'\\n'\n",
    "                post = {}\n",
    "                post['text'] = texts\n",
    "                post['gender'] = files_gender[f]\n",
    "                post['age'] = files_age[f]\n",
    "                posts.append(post)\n",
    "                tweets.append(posts)\n",
    "        tweets = list(itertools.chain(*tweets))    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "language = 'english' #spanish, english, english-nltk, dutch\n",
    "year = '2016' #2015, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = extract_tweets(language, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.feature_extraction.text import HashingVectorizer\\nfrom sklearn import cross_validation, linear_model\\nhv = HashingVectorizer(ngram_range=(1, 2), binary=True)\\ndata = []\\ngender = []\\nage = []\\nfor t in tweets:\\n    data.append(t['text'])\\n    gender.append(t['gender'])\\n    age.append(t['age'])\\n\\nfeatures = hv.transform(data)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import cross_validation, linear_model\n",
    "hv = HashingVectorizer(ngram_range=(1, 2), binary=True)\n",
    "data = []\n",
    "gender = []\n",
    "age = []\n",
    "for t in tweets:\n",
    "    data.append(t['text'])\n",
    "    gender.append(t['gender'])\n",
    "    age.append(t['age'])\n",
    "\n",
    "features = hv.transform(data)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('EmoticonSentimentLexicon.txt') as emoticon_lexicon:\n",
    "    lines = emoticon_lexicon.readlines()\n",
    "    emot_dict = {}\n",
    "    for l in lines:\n",
    "        line = l.split('\\t')\n",
    "        emot_dict[line[0]] = int(line[1].split('\\r')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "age_lexicon = {}\n",
    "gender_lexicon = {}\n",
    "\n",
    "with open('lexica/emnlp14age.csv') as age_lexicon_file:\n",
    "    age_reader = csv.reader(age_lexicon_file, delimiter=',', quotechar='\"')\n",
    "    age_reader.next()\n",
    "    age_intercept = age_reader.next()[1]\n",
    "    for row in age_reader:\n",
    "        age_lexicon[row[0]] = float(row[1])\n",
    "        \n",
    "with open('lexica/emnlp14gender.csv') as gender_lexicon_file:\n",
    "    gender_reader = csv.reader(gender_lexicon_file, delimiter=',', quotechar='\"')\n",
    "    gender_reader.next()\n",
    "    gender_intercept = gender_reader.next()[1]\n",
    "    for row in gender_reader:\n",
    "        gender_lexicon[row[0]] = float(row[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:72: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:74: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate 'str' and 'float' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-160be3bd3152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mage_lexicon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mage_lex_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mage_lexicon\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mgender_lex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'GLEX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgender_intercept\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgender_lex_count\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mage_lex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'ALEX'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_intercept\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mage_lex_count\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate 'str' and 'float' objects"
     ]
    }
   ],
   "source": [
    "import re\n",
    "gender = []\n",
    "age = []\n",
    "pos_tags = []\n",
    "tag_count = []\n",
    "i = 0\n",
    "for t in tweets:\n",
    "    text = t['text']\n",
    "    emoticons = sentiment_feature_extraction.emoticons_from_dictionary(text, emot_dict)\n",
    "    if text.split()<=0.0:\n",
    "        length = len(text.split())\n",
    "    else:\n",
    "        length = 1.0\n",
    "    caps = ('CAPS', float(sentiment_feature_extraction.caps_words(text)))\n",
    "    elongated = ('ELONGATED', float(sentiment_feature_extraction.elonganted_words(text)))\n",
    "    exclamation_interrogation_dict = sentiment_feature_extraction.exclamation_and_interrogation(text)\n",
    "    excl = ('!', exclamation_interrogation_dict['!'])\n",
    "    interr = ('?', exclamation_interrogation_dict['?'])\n",
    "    omg_count = ('OMG', len(re.findall('omg+', text, re.I)))\n",
    "    heart_count = ('<3', len(re.findall('<3+', text)))\n",
    "    lol_count = ('lol', len(re.findall('lo+l', text, re.I)))\n",
    "    lmfao_count = ('lmfao', len(re.findall('lmfa+o+', text, re.I)))\n",
    "    emoticon_count = ('EMOTCOUNT', emoticons['number_emoticons'])\n",
    "    emoticon_score = ('EMOTSCORE', emoticons['score_emoticons'])\n",
    "    mention_count = ('@COUNT', len(re.findall('@username', text)))\n",
    "    hashtag_count = ('#COUNT', len(re.findall('#', text)))\n",
    "    rt_count = ('RT', len(re.findall('RT @username', text)))\n",
    "    url_count = ('URL', len(re.findall('http[s]?://', text)))\n",
    "    pic_count = ('PIC', len(re.findall('pic.twitter.com', text)))\n",
    "    avg_text_length = ('TEXTLEN', length/len(text.split('\\n')))\n",
    "    words_length = 0\n",
    "    for word in text.split():\n",
    "        words_length += len(word)        \n",
    "    avg_word_length = ('WORDLEN', words_length/length)\n",
    "    count = count_pos(text, language)\n",
    "    count_dict = dict(count)\n",
    "    extrav_score = 0.0\n",
    "    sum_tags = ['NN', 'JJ', 'IN', 'DT']\n",
    "    sub_tags = ['PRP', 'VB', 'VBD', 'VBG', 'VBZ', 'VBP', 'VBN', 'RB', 'UH']\n",
    "    for tag in sum_tags:\n",
    "        if count_dict.has_key(tag):\n",
    "            extrav_score += count_dict[tag]\n",
    "    for tag in sub_tags:\n",
    "        if count_dict.has_key(tag):\n",
    "            extrav_score -= count_dict[tag]    \n",
    "    extraversion = ('EXTRAV', (extrav_score+100)/2.0)\n",
    "    \n",
    "    if language == 'english':\n",
    "        bf_words = 'wife|gf|girlfriend|dw'\n",
    "        gf_words = 'husband|bf|boyfriend|hubby|dh'\n",
    "    elif language == 'spanish':\n",
    "        bf_words = 'mujer|novia|esposa'\n",
    "        gf_words = 'marido|novio|esposo'\n",
    "    elif language == 'dutch':\n",
    "        bf_words = 'vrouw|vriendin'\n",
    "        gf_words = 'man|bf|vriend'\n",
    "        \n",
    "    bf_count = ('GFCOUNT', len(re.findall(bf_words, text, re.I)))\n",
    "    gf_count = ('BFCOUNT', len(re.findall(gf_words, text, re.I)))\n",
    "        \n",
    "    count.extend((caps, elongated, excl, interr, omg_count, heart_count, lol_count, lmfao_count, emoticon_count, \n",
    "            emoticon_score, mention_count, hashtag_count, rt_count, url_count, pic_count, avg_text_length, \n",
    "            avg_word_length, extraversion, bf_count, gf_count))\n",
    "    \n",
    "    if language == 'english':\n",
    "        male_rationales = ('MALRAT', len(re.findall('bro|dude|homie', text, re.I)))\n",
    "        female_rationales = ('FEMRAT', len(re.findall('cute', text, re.I)))\n",
    "        \n",
    "        gender_lex_count = 0.0\n",
    "        age_lex_count = 0.0\n",
    "        for word in text.split():\n",
    "            if word in gender_lexicon.keys():\n",
    "                gender_lex_count += gender_lexicon[word]\n",
    "            if word in age_lexicon.keys():\n",
    "                age_lex_count += age_lexicon[word]\n",
    "        gender_lex = ('GLEX', gender_intercept+gender_lex_count/length)\n",
    "        age_lex = ('ALEX', age_intercept+age_lex_count/length)\n",
    "        \n",
    "        count.extend((male_rationales, female_rationales, gender_lex, age_lex))\n",
    "    \n",
    "    tag_count.append(count)\n",
    "    gender.append(t['gender'])\n",
    "    age.append(t['age'])\n",
    "    i += 1\n",
    "    print str(i)+'/'+str(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save features\n",
    "\n",
    "import pickle\n",
    "#datapath = 'data/pan16-author-profiling-training-dataset-'+language+'-'+year+'-02-29/'\n",
    "datapath = 'data/pan15-author-profiling-training-dataset-'+language+'-'+year+'-04-23/'\n",
    "if not os.path.isdir(datapath+'data'):\n",
    "    os.makedirs(datapath+'data')\n",
    "with open(datapath+'data/tag_count.p', 'wb') as tagfile:\n",
    "    pickle.dump(tag_count, tagfile)\n",
    "with open(datapath+'data/gender.p', 'wb') as genderfile:\n",
    "    pickle.dump(gender, genderfile)\n",
    "with open(datapath+'data/age.p', 'wb') as agefile:\n",
    "    pickle.dump(age, agefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load features\n",
    "\n",
    "import pickle\n",
    "#datapath = 'data/pan16-author-profiling-training-dataset-'+language+'-'+year+'-02-29/'\n",
    "datapath = 'data/pan15-author-profiling-training-dataset-'+language+'-'+year+'-04-23/'\n",
    "with open(datapath+'data/tag_count.p', 'rb') as tagfile:\n",
    "    tag_count = pickle.load(tagfile)\n",
    "with open(datapath+'data/gender.p', 'rb') as genderfile:\n",
    "    gender = pickle.load(genderfile)\n",
    "with open(datapath+'data/age.p', 'rb') as agefile:\n",
    "    age = pickle.load(agefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "pos_tags = []\n",
    "for post in tag_count: \n",
    "    for tag in post:\n",
    "        if tag[0] not in pos_tags:\n",
    "            pos_tags.append(tag[0])\n",
    "print pos_tags\n",
    "\n",
    "complete_tag_count = []\n",
    "for post in tag_count:\n",
    "    p = dict(post)\n",
    "    for pos in pos_tags:\n",
    "        if pos not in p:\n",
    "            post.append((pos, 0))\n",
    "    post = sorted(post)\n",
    "    complete_tag_count.append([i[1] for i in post])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_total = np.array(complete_tag_count)\n",
    "gender_total = np.array(gender)\n",
    "#remove_index = pos_tags.index('EXTRAV')\n",
    "#filtered_tags = np.zeros(shape=(len(tag_total),65))\n",
    "#for t in range(0, len(tag_total)-1):\n",
    "#    filtered_tags[t] = np.delete(tag_total[t], remove_index)\n",
    "#tag_total = filtered_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, svm, linear_model, tree, ensemble, naive_bayes, neighbors, gaussian_process, grid_search\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "age_total = np.array(age)\n",
    "#features_total = np.array(features)\n",
    "\n",
    "predicted_class = age_total # gender_total, age_total\n",
    "\n",
    "clf1 = linear_model.LogisticRegression()\n",
    "clf2 = ensemble.RandomForestClassifier(n_estimators=100)\n",
    "clf3 = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf4 = svm.SVC(kernel='linear', probability=True, C=0.05)\n",
    "clf5 = naive_bayes.GaussianNB()\n",
    "clf6 = naive_bayes.BernoulliNB()\n",
    "clf7 = ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf8 = ensemble.AdaBoostClassifier(n_estimators=100)\n",
    "clf9 = OneVsRestClassifier(clf4)\n",
    "\n",
    "eclf = ensemble.VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3), ('kn', clf4),\n",
    "                                             ('svcl', clf5), ('gnb', clf6), ('gbc', clf7), ('ada', clf8), ('multi', clf9)], voting='soft')\n",
    "eclf2 = ensemble.VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3), ('kn', clf4),\n",
    "                                             ('svcl', clf5), ('gnb', clf6), ('gbc', clf7), ('ada', clf8), ('multi', clf9)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of folds n_folds=3 greater than the number of samples: 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9cec1c7be61f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, eclf, eclf2], ['Logistic Regression', 'Random Forest',\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'Decision Tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SVC Linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Gaussian NB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bernoulli NB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Gradient Boosting Classifier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AdaBoost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'One vs Rest'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     'Soft Voting Ensemble', 'Hard Voting Ensemble']):\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m     def __init__(self, n, n_folds=3, shuffle=False,\n\u001b[0;32m    313\u001b[0m                  random_state=None):\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n, n_folds, shuffle, random_state)\u001b[0m\n\u001b[0;32m    243\u001b[0m             raise ValueError(\n\u001b[0;32m    244\u001b[0m                 (\"Cannot have number of folds n_folds={0} greater\"\n\u001b[1;32m--> 245\u001b[1;33m                  \" than the number of samples: {1}.\").format(n_folds, n))\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of folds n_folds=3 greater than the number of samples: 0."
     ]
    }
   ],
   "source": [
    "cv = cross_validation.KFold(tag_total.shape[0], 3)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, eclf, eclf2], ['Logistic Regression', 'Random Forest',\n",
    "    'Decision Tree', 'SVC Linear','Gaussian NB', 'Bernoulli NB', 'Gradient Boosting Classifier', 'AdaBoost', 'One vs Rest', \n",
    "    'Soft Voting Ensemble', 'Hard Voting Ensemble']):\n",
    "    scores = cross_validation.cross_val_score(clf, tag_total, predicted_class, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(<152x1048576 sparse matrix of type '<type 'numpy.float64'>'\n\twith 220223 stored elements in Compressed Sparse Row format>, dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-02fee7b092e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                  \u001b[1;34m'Decision Tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SVC Linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Gaussian NB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bernoulli NB'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                 'Gradient Boosting Classifier', 'AdaBoost', 'One vs Rest', 'Voting Ensemble', 'Grid Search']):\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_total\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %0.2f (+/- %0.2f) [%s]\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1420\u001b[0m         \u001b[0mArray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mscores\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcross\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1421\u001b[0m     \"\"\"\n\u001b[1;32m-> 1422\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \"\"\"\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 122\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(<152x1048576 sparse matrix of type '<type 'numpy.float64'>'\n\twith 220223 stored elements in Compressed Sparse Row format>, dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "\"\"\"cv = cross_validation.KFold(tag_total.shape[0], 3)\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, clf8, clf9, eclf, grid], ['Logistic Regression', 'Random Forest',\n",
    "                                                 'Decision Tree', 'SVC Linear','Gaussian NB', 'Bernoulli NB', \n",
    "                                                'Gradient Boosting Classifier', 'AdaBoost', 'One vs Rest', 'Voting Ensemble', 'Grid Search']):\n",
    "    scores = cross_validation.cross_val_score(clf, features, predicted_class, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf8.fit(tag_total, predicted_class)\n",
    "for c in range(1,len(clf8.feature_importances_)):\n",
    "    print pos_tags[c], clf8.feature_importances_[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf3.fit(tag_total, gender_total)\n",
    "from sklearn.externals.six import StringIO\n",
    "with open(\"gender.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf3, out_file=f, filled=True, class_names=['Female', 'Male'], feature_names=pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
